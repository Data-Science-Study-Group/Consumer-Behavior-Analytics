---
title: "Data Processing"
author: "Francis Troy Kirinhakone & Carlos HeHe"
date: "11/12/2018"
output: html_document
---
#Import library and datasets
```{r}
library(tidyverse)
library(ggplot2)
library(date)
customers = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_customers_dataset.csv")
geolocation = readxl::read_xls(path = "~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_geolocation_dataset.xls")
order_items = readxl::read_xls(path = "~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_order_items_dataset.xls")
order_payments = readxl::read_xls(path = "~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_order_payments_dataset.xls")
order_reviews = readxl::read_xls(path = "~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_order_reviews_dataset.xls")
orders = readxl::read_xls(path = "~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_orders_dataset.xls")
products = readxl::read_xls(path = "~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_products_dataset.xls")
sellers = readxl::read_xls(path = "~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_sellers_dataset.xls")
product_category = readxl::read_xls(path = "~/GitHub/datasci_proj/brazilian-ecommerce_ver6/product_category_name_translation.xls")
```

#Description of the attributes of each dataset
```{r}
names(customers)
```
```{r}
names(geolocation)
```
```{r}
names(order_items)
```
```{r}
order_payments %>%
  names()
```
```{r}
order_reviews %>%
  names()
```
```{r}
orders %>% names()
```
```{r}
product_category %>% names()
```
```{r}
products %>% names()
```
```{r}
sellers %>% names()
```

#Exploratory Data Analysis Stage
```{r}
order_items$price %>%
  summary()

order_items %>% arrange(desc(price)) %>%
   select(price, everything()) #place price as the first column
```
We see that there is an outlier at the max of 6735. Maybe we should exclude this point?

#What the correlation between customer_id and price?

Prep the dataframe, temp, to plot.
```{r}
temp = data.frame(customers$customer_unique_id)
temp%>%mutate(customers$customer_id)->temp
temp%>%mutate(order_items$price) -> temp
temp%>%arrange(customers.customer_unique_id)
temp%>%arrange(customers$customer_id)

##find class type
class(temp$customers.customer_unique_id)#factor type...need to convert to string
class(temp$`customers$customer_id`)
class(temp$`order_items$price`)
```
Now use the plot fuction to product a scatter plot(x,y) x = customer_unique_id, y = order_items$price
```{r}
plot(temp$customers.customer_unique_id,temp$`order_items$price`, 
     bty=n,
     col="red",
     main="Customer to Item Price",
     xlab="Customer_Unique_id",
     ylab="Item_Price",
     cex.axis=.5,
     pch=16)

qplot(data=temp,x=temp$customers.customer_unique_id,y=temp$`order_items$price`)
```
Looking at the plot we see there are a few outliers. So we can say that there's a few high end purchases that are infrequent. These points may skew our model and should be exluded.

Since most of the data is under 2000 approx. Lets filter those points out.
```{r}
df_cust_price = temp

df_cust_price %>% 
  filter(`order_items$price` < 5) -> df_cust_price_new

df_cust_price_new
  
qplot(df_cust_price_new, aes(df_cust_price_new$customers.customer_unique_id, df_cust_price_new$`order_items$price`))
```


Curious if we group the customers by zipcode.
```{r}
temp %>%
  mutate(customers$customer_zip_code_prefix) %>%
  group_by(customers$customer_zip_code_prefix) -> temp

temp %>% arrange(`customers$customer_zip_code_prefix`) %>%
    select(`customers$customer_zip_code_prefix`,everything())

ggplot(temp, aes(x=temp$customers.customer_unique_id,y=temp$`order_items$price`))

qplot(x=temp$customers.customer_unique_id,y=temp$`order_items$price`,data=temp, color=temp$`customers$customer_zip_code_prefix`) + geom_point() + coord_fixed(2)
```
How have orders progressed over time?
Let's find out with payments dataset for y val, and x = order_purchase_timestamp.
```{r}
df = data.frame(order_payments$payment_value,orders$order_purchase_timestamp)

qplot(x=df$orders.order_purchase_timestamp,y=df$order_payments.payment_value,data=df, color="red")
```
We see that we have a gap in the data before jan 2017. 

Curious of the frequency of buyers from various zip codes.
```{r}
as.data.frame(table(customers$customer_zip_code_prefix)) %>% 
  arrange(desc(Freq)) -> zip_df

zip_df

ggplot(zip_df, aes(x=zip_df$Var1)) + geom_bar()

animals = c("cat","dog","bird","cat")
class(animals)
ggplot(data.frame(animals), aes(x=animals)) + geom_bar()
```

#Price to zipcode

```{r}
df = data.frame(customers$customer_id,order_payments$payment_type)
df
table(df$order_payments.payment_type) %>%
barplot()

df %>% mutate(orders$customer_id, customers$customer_city, customers$customer_state) -> df
summary(df)

qplot(x = df$`customers$customer_city`,y = df$order_payments.payment_type)

table(df$`customers$customer_city`, df$order_payments.payment_type) -> tbl_1
as.data.frame.matrix(tbl_1) -> new_df

View(new_df)

rownames_to_column(df = new_df,var = "city_name") %>%
  filter(debit_card > 0) %>% 
  column_to_rownames('city_name') -> df_debitcard


#barplot(t(as.matrix(df_debitcard)), beside = TRUE )
df_debitcard %>%
  as.matrix() %>%
  t() %>%
  barplot(beside = TRUE)

df_debitcard$city = row.names(df_debitcard)

?`stringr-package`
```

Machine Learning
need to find the shipping speed of dates.
```{r}
orders -> df

?date
```

#DELIVERY SPEED
```{r}
library(lubridate)
library(zoo)
library(tidyverse)
library(stringr)

#load data
data = read.csv("~/Github/datasci_proj/delivery_speed/olist_orders_dataset.csv")

#get the two columns we need
dates = data[,c(4,6)]

#take on the date and time and put each as a separate new column
dates$parsed_purchased_date = 
  lapply(dates[,1], function(x) (str_split_fixed(x," ",2)[1]))

dates$parsed_purchased_time = 
  lapply(dates[,1], function(x) (str_split_fixed(x," ",2)[2]))

#same as above
dates$pasred_deliver_carrier_date = 
  lapply(dates[,2], function(x) (str_split_fixed(x," ",2)[1]))

dates$pasred_deliver_carrier_time = 
  lapply(dates[,2], function(x) (str_split_fixed(x," ",2)[2]))

#calculate the difference in days
d1 = strptime(dates[,3],format = "%m/%d/%Y")
d2 = strptime(dates[,5],format = "%m/%d/%Y")
dates$day_difference = round(difftime(d1,d2, units = "days") * -1,digit = 0)

#difference in time
t1 = strptime(dates[,4], format = "%H:%M")
t2 = strptime(dates[,6], format = "%H:%M")
dates$time_difference_min = difftime(t2,t1, units = "min") #as.numeric
dates$time_difference_min = lapply(dates[,8], function(x)(if(is.na(x) != TRUE && x < 0){x * -1} else{x})) #turn all values positive



````





