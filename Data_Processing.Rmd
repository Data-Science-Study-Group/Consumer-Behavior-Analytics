---
title: "Data Processing"
author: "Francis Troy Kirinhakone & Carlos HeHe"
date: "11/12/2018"
output: html_document
---
#Import library and datasets
```{r}
library(tidyverse)
library(ggplot2)
library(date)
customers = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_customers_dataset.csv")
geolocation = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_geolocation_dataset.csv")
order_items = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_order_items_dataset.csv")
order_payments = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_order_payments_dataset.csv")
order_reviews = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_order_reviews_dataset.csv")
orders = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_orders_dataset.csv",na.strings = c("","NA"))
products = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_products_dataset.csv")
sellers = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_sellers_dataset.csv")
product_category = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/product_category_name_translation.csv")
```

#Description of the attributes of each dataset
```{r}
names(customers)
```
```{r}
names(geolocation)
```
```{r}
names(order_items)
```
```{r}
order_payments %>%
  names()
```
```{r}
order_reviews %>%
  names()
```
```{r}
orders %>% names()
```
```{r}
product_category %>% names()
```
```{r}
products %>% names()
```
```{r}
sellers %>% names()
```



#Exploratory Data Analysis Stage
```{r}
order_items$price %>%
  summary()

order_items %>% arrange(desc(price)) %>%
   select(price, everything()) #place price as the first column
```
We see that there is an outlier at the max of 6735. Maybe we should exclude this point?

#What the correlation between customer and price?
```{r}
merge(orders,order_items, by="order_id") -> df1
df1 <- merge(df1, customers, by="customer_id")
```

Link price to customer + plot
```{r}
df1 %>% 
  filter(price < 7000 ) -> df2
ggplot(df2, aes(x=customer_id, y=price)) + geom_point() + geom_smooth()
```
Analysis: Looking at the plot we see that the majority of the purchases were under $2000, a few points are greater than $6k which we might want to exclude.

#How have orders progressed over time?
Let's find out with payments dataset for y val, and x = order_purchase_timestamp.
```{r}
df <- df1
qplot(x=df$order_purchase_timestamp,y=df$price,data=df, color="red")
```
Analysis: 

Group by top 5 cities
```{r}
#copy over dataframe
group_by_city_df <- df1

#group by city
group_by_city_df %>%
group_by(customer_city) -> group_by_city_df

#remap df to have city at front
group_by_city_df %>% 
    select(customer_city,everything()) -> group_by_city_df

#find the frequency of orders from each city
table(group_by_city_df$customer_city) %>%
  as.data.frame() %>%
  arrange(desc(Freq)) -> tb_city

#only show top 5 cities with most frequent orders
tb_city[1:5,] -> tb_city

#see top 5 cities as a plot
ggplot(data=tb_city, aes(x=order(Var1),y=Freq,color=Var1)) + geom_col()
```
#What does each city look like with their customers?
```{r}
#set
cust_city_5 <- df1

#top 5
target <- c("belo horizonte", "brasilia", "curitiba","rio de janeiro","sao paulo")

#filter known top 5 cities
cust_city_5 %>%
  filter(customer_city %in% target) -> cust_city_5

cust_city_5

ggplot(cust_city_5,aes(x=cust_city_5$customer_id,y=cust_city_5$price,color=customer_city)) + facet_grid(cols=vars(customer_city)) + geom_point()
```

```{r}
just_top <- cust_city_5

just_top %>%
  filter(customer_city %in% c("sao paulo")) -> just_top
just_top

regressor <- lm(just_top$price ~ just_top$customer_id)
```
```{r}
bott_city <- cust_city_5

bott_city %>%
  filter(customer_city %in% c("curitiba")) -> bott_city
bott_city %>%
  filter(price < 200) -> bott_city

qplot(data=bott_city,x=bott_city$order_id,y=bott_city$price)

test = bott_city

ggplot(data=bott_city,aes(x=as.numeric(order_purchase_timestamp),y=price)) + 
  geom_point()+
  geom_smooth(method="gam")

qplot(data=test,x=as.numeric(order_purchase_timestamp),y=price, geom = c("point","smooth"))
      
regressor <- lm(bott_city$price ~ bott_city$)
summary(regressor)
plot(regressor)
```



Curious of the frequency of buyers from various zip codes.
```{r}
as.data.frame(table(customers$customer_zip_code_prefix)) %>% 
  arrange(desc(Freq)) -> zip_df

zip_df

ggplot(zip_df, aes(x=zip_df$Var1)) + geom_bar()

animals = c("cat","dog","bird","cat")
class(animals)
ggplot(data.frame(animals), aes(x=animals)) + geom_bar()
```

#Price to zipcode

```{r}
df = data.frame(customers$customer_id,order_payments$payment_type)
df
table(df$order_payments.payment_type) %>%
barplot()

df %>% mutate(orders$customer_id, customers$customer_city, customers$customer_state) -> df
summary(df)

qplot(x = df$`customers$customer_city`,y = df$order_payments.payment_type)

table(df$`customers$customer_city`, df$order_payments.payment_type) -> tbl_1
as.data.frame.matrix(tbl_1) -> new_df

View(new_df)

rownames_to_column(df = new_df,var = "city_name") %>%
  filter(debit_card > 0) %>% 
  column_to_rownames('city_name') -> df_debitcard


#barplot(t(as.matrix(df_debitcard)), beside = TRUE )
df_debitcard %>%
  as.matrix() %>%
  t() %>%
  barplot(beside = TRUE)

df_debitcard$city = row.names(df_debitcard)

?`stringr-package`
```

#Split into quarters
```{r}
#create quarters
df_q4_2016 <- data.frame(df1)
df_q1_2017 <- data.frame(df1)
df_q2_2017<- df1
df_q3_2017<- df1
df_q4_2017<- df1
df_q1_2018<- df1
df_q2_2018<- df1
df_q3_2018<- df1


orders_Q1 <- orders #set Q1 with orders
#split orders purchased into distinct columns
orders_Q1$order_purchase_timestamp %>%
  str_split_fixed(pattern = " ", 2) -> temp

#keep only dates
temp[,1] -> temp

#push back onto Q1
mutate(orders_Q1, temp) -> orders_Q1
View(orders_Q1)
class(orders_Q1$temp)#is character type, must be date type

orders_Q1$temp <- as.Date(orders_Q1$temp, format= "%Y-%m-%d")
#sort out only Q1 of 2017
subset(orders_Q1, temp > "2014-01-01" & temp < "2017-01-01") -> 

summary(orders_Q1)
```
```{r}
summary(orders)
```



#Split into training and test set

Machine Learning
need to find the shipping speed of dates.
```{r}
orders -> df

?date
```

EDA: Orders
```{r}
View(orders)
orders[7,6] %>%
  View()
```


#DELIVERY TIME
```{r}
library(lubridate)
library(zoo)
library(tidyverse)
library(stringr)

#load data
#data = orders
data = read.csv("~/GitHub/datasci_proj/delivery_speed/olist_orders_dataset.csv")

#get the two columns we need
dates = data[,c(4,6)]

#take on the date and time and put each as a separate new column
dates$parsed_purchased_date = 
  lapply(dates[,1], function(x) (str_split_fixed(x," ",2)[1]))

dates$parsed_purchased_time = 
  lapply(dates[,1], function(x) (str_split_fixed(x," ",2)[2]))

#same as above
dates$pasred_deliver_carrier_date = 
  lapply(dates[,2], function(x) (str_split_fixed(x," ",2)[1]))

dates$pasred_deliver_carrier_time = 
  lapply(dates[,2], function(x) (str_split_fixed(x," ",2)[2]))

#example on how to take the difference in days off two dates.
#date_strings = c("1/2/2013", "1/3/2013")
#datetimes = strptime(date_strings, format = "%m/%d/%Y")
#difftime(datetimes[1], datetimes[2], units = "days") # days

#calculate the difference in days
d1 = strptime(dates[,3],format = "%m/%d/%Y")
d2 = strptime(dates[,5],format = "%m/%d/%Y")
dates$day_difference = round(difftime(d1,d2, units = "days") * -1,digit = 0)

#difference in time
t1 = strptime(dates[,4], format = "%H:%M")
t2 = strptime(dates[,6], format = "%H:%M")
dates$time_difference_min = difftime(t2,t1, units = "min") #as.numeric
dates$time_difference_min = lapply(dates[,8], function(x)(if(is.na(x) != TRUE && x < 0){x * -1} else{x})) #turn all values positive

#get total difference in of days and minutes combined
temp = data[,c(1,2)] #get the first two columns
temp$customer_id = NULL #erase the second column
temp$days = dates$day_difference
temp$min = dates$time_difference_min
temp$days_min = temp$days * 1440 #24 * 60 = 1440
temp$total_min = temp$days_min + as.numeric(temp$min) #add all the minutes together

total_diff_min = temp[c(1,5)]

dates
total_diff_min

```

#TOP 5 STATES
```{r}
library(tidyverse)
library(dplyr)

#load dataset
data = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_customers_dataset.csv")
orders = read.csv("~/GitHub/datasci_proj/brazilian-ecommerce_ver6/olist_order_items_dataset.csv")

#find out most freq customers by state
state = table(data$customer_state)
state = as.data.frame(state)
freq_state = state[with(state,order(-Freq)),]

freq_state$ID <- seq.int(nrow(freq_state)) #create index column
rownames(freq_state) = freq_state[,3]#replace column 0 with index column
freq_state$ID <- NULL #erase our index column

#only plot the top 5
freq_state[1:5,] -> plot_state_freq
names(plot_state_freq) = c("State", "Frequency")
ggplot(data=plot_state_freq,aes(x=State,y=Frequency)) + geom_bar(stat="identity")
plot_state_freq %>% arrange(Frequency) -> plot_state_freq
ggplot(data=plot_state_freq,aes(x=reorder(State,-Frequency),y=Frequency)) + geom_col() + ggtitle("Most Frequent Purchases by State")
  

```

carlos test